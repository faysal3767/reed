{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic and advanced modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from IPython.core.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires to save data as csv with today's date\n",
    "today = datetime.today().strftime(\"%d_%b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"nest_asyncio.apply()\" code snippet, otherwise it throws \"RuntimeError: asyncio.run() cannot be called from a running event loop\"\n",
    "nest_asyncio.apply()\n",
    "def scrapeByProvider(providerUrl):\n",
    "    \"\"\"It will scrape any provider data, provided that link of the provider is given as input to the function\"\"\"\n",
    "    startTime = time.time()\n",
    "    \n",
    "    # Initialize empty list of variables to be scraped\n",
    "    courseLink = []\n",
    "    courseTitle = []\n",
    "    courseProvider = []\n",
    "    subTitle = []\n",
    "    unitSold = []\n",
    "    offerPrice = []\n",
    "    originalPrice = []\n",
    "    savings = []\n",
    "    soldOrEnq = []\n",
    "    haveCpd = []\n",
    "    haveProfQual = []\n",
    "    isRegulated = []\n",
    "    awrBodyQualName = []\n",
    "    awrBodyName = []\n",
    "    cpdAccreditedBy = []\n",
    "    othersAsCpd = []\n",
    "    \n",
    "    # Get the no of pages to scrape. It requests to a provider url to scrape the number of total courses it has.\n",
    "    responseStopPage = requests.get(providerUrl)\n",
    "    soupStopPage = BeautifulSoup(responseStopPage.content,\"html.parser\")\n",
    "    totalCoursesStr = soupStopPage.find(\"span\",class_=\"h1\").text.strip()\n",
    "    totalCoursesStr = totalCoursesStr.replace(\",\",\"\") # Remove comma if any\n",
    "    totalCoursesInt = int(totalCoursesStr) # Convert course no into int from string\n",
    "    stopPageFloat = np.ceil(totalCoursesInt/100) # Returns float\n",
    "    stopPageInt = np.int(stopPageFloat) # Converts into int, since range function requires integer data type\n",
    "    \n",
    "    \n",
    "    # This portion scrapes all the indvidual courses link of that provider\n",
    "    async def fetch(session, providerUrl):\n",
    "        async with session.get(providerUrl) as response:\n",
    "            return await response.text()\n",
    "        \n",
    "    async def main():\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            # Iterate over the stop page to scrape all the indvidual courses link in most popular basis with page size 100\n",
    "            for page in range(1,stopPageInt+1):\n",
    "                htmlCourseLink = await fetch(session, providerUrl + f\"?pageno={page}&sortby=MostPopular&pagesize=100\")\n",
    "                soupCourseLink = BeautifulSoup(htmlCourseLink,\"html.parser\")\n",
    "                # Scrapes individual course link\n",
    "                for lnk in soupCourseLink.find_all(\"h2\",class_=\"mt-4 mt-sm-1 mr-5 mb-0\"):\n",
    "                    # Need to create absolute url to make request to each individual course later\n",
    "                    courseLink.append(str(\"https://www.reed.co.uk\")+lnk.find(\"a\").get(\"href\"))\n",
    "                    \n",
    "    asyncio.run(main())\n",
    "    \n",
    "    # Information parsing. Scrape all the variables except courseLink by sending requests to courseLink\n",
    "    async def fetch(session, providerUrl):\n",
    "        async with session.get(providerUrl) as response:\n",
    "            return await response.text()\n",
    "        \n",
    "        \n",
    "    async def main():\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            # Count the no of requests\n",
    "            req = 0\n",
    "            # Extract provider name from providerUrl to print during requests count\n",
    "            providerName = providerUrl.split(\"/\")[4].title()\n",
    "            # Sending requests to each course link to extract required variables\n",
    "            for lnk,reqCount in zip(courseLink,np.arange(1,len(courseLink)+1)):\n",
    "                htmlInfo = await fetch(session, lnk)\n",
    "                req = req+1\n",
    "                print(f\"{providerName} => Requests Completed: {req} out of {len(courseLink)}\")\n",
    "                soupInfo = BeautifulSoup(htmlInfo,\"html.parser\")\n",
    "                # Clear all the outputs except the current one in notebook console\n",
    "                clear_output(wait=True)\n",
    "                \n",
    "                # Extract title\n",
    "                try:\n",
    "                    titleTag = soupInfo.find(\"h1\")\n",
    "                    courseTitle.append(titleTag.text)\n",
    "                except:\n",
    "                    courseTitle.append(\"missing\")\n",
    "                \n",
    "                # Extract subtitle\n",
    "                try:\n",
    "                    subTitleTag = soupInfo.find(\"h2\")\n",
    "                    subTitle.append(subTitleTag.text)\n",
    "                except:\n",
    "                    subTitle.append(\"missing\")\n",
    "\n",
    "                \n",
    "                # Extract offer price\n",
    "                try:\n",
    "                    offerPriceTag = soupInfo.find(\"span\",class_=\"current-price\")\n",
    "                    offerPrice.append(offerPriceTag.text)\n",
    "                except:\n",
    "                    offerPrice.append(\"missing\")\n",
    "                \n",
    "                # Extract unit sale\n",
    "                try:\n",
    "                    unitSoldTag = soupInfo.find_all('strong')[1]\n",
    "                    unitSold.append(unitSoldTag.text)\n",
    "                except:\n",
    "                    unitSold.append(\"missing\")\n",
    "                \n",
    "                \n",
    "                # Extract original price\n",
    "                try:\n",
    "                    originalPriceTag = soupInfo.find(\"small\",class_=\"vat-status\")\n",
    "                    originalPrice.append(originalPriceTag.text)\n",
    "                except:\n",
    "                    originalPrice.append(\"missing\")\n",
    "                \n",
    "                # Extract providers\n",
    "                try:\n",
    "                    providerTag = soupInfo.find(\"section\",class_=\"sidebar-actions\").find(\"a\",class_=\"provider-link\")\n",
    "                    courseProvider.append(providerTag.text)\n",
    "                except:\n",
    "                    courseProvider.append(\"missing\")\n",
    "                \n",
    "                # Extract savings\n",
    "                try:\n",
    "                    savingsTag = soupInfo.find(\"span\",class_=\"icon-savings-tag price-saving\")\n",
    "                    savings.append(savingsTag.text)\n",
    "                except:\n",
    "                    savings.append(\"missing\")\n",
    "                \n",
    "                # Extract if the course is sold or enquired\n",
    "                try:\n",
    "                    soldOrEnqTag = soupInfo.find_all(\"div\",class_=\"summary-content\")[-1]\n",
    "                    soldOrEnq.append(soldOrEnqTag.text.strip())\n",
    "                except:\n",
    "                    soldOrEnq.append(\"missing\")\n",
    "                    \n",
    "                # Does the course have cpd? \n",
    "                try:\n",
    "                    cpdTag = soupInfo.find(\"div\", class_=\"badge badge-dark badge-cpd mt-2\")\n",
    "                    haveCpd.append(\"yes\" if cpdTag else \"no\")\n",
    "                    \n",
    "                    # Other certification termed as CPD\n",
    "                    if cpdTag:\n",
    "                        cpdAccreditedByTag = soupInfo.find(\"div\",class_=\"col\").find_all(\"div\")[-1]\n",
    "                        othersAsCpd.append(cpdAccreditedByTag.text.strip().split(\"by\")[-1].strip())\n",
    "                    else:\n",
    "                        othersAsCpd.append(\"missing\")\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "                \n",
    "                # Does the course have professional qualification?\n",
    "                try:\n",
    "                    profQualTag = soupInfo.find(\"div\", class_=\"badge badge-dark badge-professional mt-2\")\n",
    "                    haveProfQual.append(\"yes\" if profQualTag else \"no\")\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Is the course qualification regulated?\n",
    "                try:\n",
    "                    reguTag = soupInfo.find(\"div\", class_=\"badge badge-dark badge-regulated mt-2\")\n",
    "                    isRegulated.append(\"yes\" if reguTag else \"no\")\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Extract awarding body qualification name if any\n",
    "                try:\n",
    "                    awrBodyQualNameTag = soupInfo.find(\"div\",class_=\"col\")\n",
    "                    awrBodyQualName.append(awrBodyQualNameTag.find_all(\"div\")[0].text.strip() if awrBodyQualNameTag else \"missing\")\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Extract awarding body name if any\n",
    "                try:\n",
    "                    awrBodyNameTag = soupInfo.find(\"div\",class_=\"col\")\n",
    "                    awrBodyName.append(awrBodyNameTag.find_all(\"div\")[1].text.strip() if awrBodyNameTag else \"missing\")\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Who provides cpd accreditation?\n",
    "                try:\n",
    "                    # If the tag text contains \"CPD\", we will then extract the cpd provider\n",
    "                    cpdAccreditedByTag = soupInfo.find(\"div\",class_=\"col\").find_all(\"div\")[-1]\n",
    "                    # This filters out any certification providers except cpd\n",
    "                    if cpdAccreditedByTag.findAll(text=re.compile(\"CPD\"), limit=1):\n",
    "                        cpdAccreditedBy.append(cpdAccreditedByTag.text.strip().split(\"by\")[-1].strip())\n",
    "                    else:\n",
    "                        cpdAccreditedBy.append(\"missing\")\n",
    "                except:\n",
    "                    cpdAccreditedBy.append(\"missing\")\n",
    "\n",
    "    asyncio.run(main())\n",
    "    \n",
    "    # Now all the variables extraction is done. Create a primary dataframe off those extracted variables\n",
    "    primaryDf = pd.DataFrame({\n",
    "        \"courseTitle\":courseTitle,\n",
    "        \"courseLink\": courseLink,\n",
    "        \"subTitle\":subTitle,\n",
    "        \"courseProvider\":courseProvider,\n",
    "        \"offerPrice\":offerPrice,\n",
    "        \"originalPrice\":originalPrice,\n",
    "        \"savings\":savings,\n",
    "        \"unitSold\":unitSold,\n",
    "        \"soldOrEnq\":soldOrEnq,\n",
    "        \"haveCpd\":haveCpd,\n",
    "        \"othersAsCpd\":othersAsCpd,\n",
    "        \"cpdAccreditedBy\":cpdAccreditedBy,\n",
    "        \"haveProfQual\":haveProfQual,\n",
    "        \"isRegulated\":isRegulated,\n",
    "        \"awrBodyQualName\":awrBodyQualName,\n",
    "        \"awrBodyName\":awrBodyName\n",
    "    })\n",
    "    \n",
    "    \"\"\"Data processing, cleaning, and feature engineering.\n",
    "    We will create a new dataframe for this purpose.\n",
    "    Because we do not want to mutate the original dataframe\"\"\"\n",
    "    # Create an empty dataframe to store cleaned data\n",
    "    cleanedDf = pd.DataFrame()\n",
    "    # Extract id from courseLink\n",
    "    cleanedDf.insert(loc=0, value=primaryDf.courseLink.str.split(\"/\").str.get(5).str.replace(\"#\",\"\"),column=\"courseId\")\n",
    "    \n",
    "    # Clean original price. Remove text from digits\n",
    "    removeStringsFromOriginalPrice = primaryDf.originalPrice.apply(lambda x: \"\".join(re.findall(r\"[0-9\\.]\",x)))\n",
    "    # Convert empty strings to nan and fill nan with 0\n",
    "    cleanedDf[\"originalPrice\"] = pd.to_numeric(removeStringsFromOriginalPrice,errors=\"coerce\").fillna(0)\n",
    "    \n",
    "    # Clean offer price\n",
    "    removeCommaAndPoundFromOfferPrice = primaryDf.offerPrice.str.replace(\"Â£\",\"\").str.replace(\",\",\"\")\n",
    "    # Convert any strings (FREE) to nan and fill nan with 0\n",
    "    cleanedDf[\"offerPrice\"] = pd.to_numeric(removeCommaAndPoundFromOfferPrice, errors=\"coerce\").fillna(0)\n",
    "    \n",
    "    # Clean savings. Keep the digits only\n",
    "    removeStringsFromSavings = primaryDf.savings.apply(lambda x: \"\".join(re.findall(r\"[0-9\\.]\",x)))\n",
    "    # Convert empty strings to nan and fill nan with 0 and cast into integer\n",
    "    cleanedDf[\"savings(%)\"] = pd.to_numeric(removeStringsFromSavings, errors=\"coerce\").fillna(0).astype(int)\n",
    "    \n",
    "    # Clean awarding body name\n",
    "    cleanedDf[\"awrBodyName\"] = primaryDf.awrBodyName.str.split(\"\\n\").str.get(1).fillna(\"missing\")\n",
    "    \n",
    "    # Remove comma from unitSold.\n",
    "    removeCommaFromUnitSold = primaryDf.unitSold.str.replace(\",\",\"\")\n",
    "    # Also cast non digits to nan and then replace nan with 0, and cast into integer\n",
    "    cleanedDf[\"unitSold\"] = pd.to_numeric(removeCommaFromUnitSold, errors=\"coerce\").fillna(0).astype(int)\n",
    "    \n",
    "    # Extract course level from awarding body qualification name and fill nan with missing\n",
    "    cleanedDf[\"courseLevel\"] = pd.to_numeric(primaryDf.awrBodyQualName.str.split(\" \").str.get(1), errors=\"coerce\").fillna(\"missing\")\n",
    "    \n",
    "    # Create the finalDF with required variables from primaryDf and cleanedDf\n",
    "    finalDf = pd.DataFrame({\n",
    "        \"courseId\":cleanedDf.courseId,\n",
    "        \"courseTitle\":primaryDf.courseTitle,\n",
    "        \"subTitle\":primaryDf.subTitle,\n",
    "        \"courseLink\":primaryDf.courseLink,\n",
    "        \"courseProvider\":primaryDf.courseProvider,\n",
    "        \"unitSold\":cleanedDf.unitSold,\n",
    "        \"soldOrEnq\":primaryDf.soldOrEnq,\n",
    "        \"offerPrice\":cleanedDf.offerPrice,\n",
    "        \"originalPrice\":cleanedDf.originalPrice,\n",
    "        \"haveCpd\":primaryDf.haveCpd,\n",
    "        \"cpdAccreditedBy\":cpdAccreditedBy,\n",
    "        \"othersAsCpd\":primaryDf.othersAsCpd,\n",
    "        \"haveProfQual\":primaryDf.haveProfQual,\n",
    "        \"isRegulated\":primaryDf.isRegulated,\n",
    "        \"awrBodyName\":cleanedDf.awrBodyName,\n",
    "        \"awrBodyQualName\":primaryDf.awrBodyQualName,\n",
    "        \"courseLevel\": cleanedDf.courseLevel\n",
    "    })\n",
    "    \n",
    "    # Calculate the program execution time in mins\n",
    "    endTime = time.time()\n",
    "    durationInMins = np.round((endTime-startTime)/60,2)\n",
    "    print(f\"{finalDf.courseProvider.iloc[0]} => Time Required to Scrape {finalDf.shape[0]} Records => {durationInMins} Minutes\")\n",
    "    return finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Education => Time Required to Scrape 429 Records => 5.73 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape one education. Provider url is given as input to the function\n",
    "oneEducation = scrapeByProvider(\"https://www.reed.co.uk/courses/one-education/p1812\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Gate => Time Required to Scrape 365 Records => 4.08 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape course gate\n",
    "courseGate = scrapeByProvider(\"https://www.reed.co.uk/courses/course-gate/p1834\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Janets => Time Required to Scrape 432 Records => 4.69 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape janets\n",
    "janets = scrapeByProvider(\"https://www.reed.co.uk/courses/janets/p1778\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euston College => Time Required to Scrape 76 Records => 1.33 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape euston college\n",
    "eustonCollege = scrapeByProvider(\"https://www.reed.co.uk/courses/euston-college/p2128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Express Ltd => Time Required to Scrape 35 Records => 0.57 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape training express limited\n",
    "trainingExpress = scrapeByProvider(\"https://www.reed.co.uk/courses/training-express-ltd/p2079\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be-a.co.uk => Time Required to Scrape 338 Records => 3.6 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape beaco\n",
    "beaco = scrapeByProvider(\"https://www.reed.co.uk/courses/be-acouk/p545\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPD Courses => Time Required to Scrape 756 Records => 8.27 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape CPD courses\n",
    "cpdCourses = scrapeByProvider(\"https://www.reed.co.uk/courses/cpd-courses/p1534\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brentwood Open learning College => Time Required to Scrape 226 Records => 2.64 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape brentwood\n",
    "brentwood = scrapeByProvider(\"https://www.reed.co.uk/courses/brentwood-open-learning-college/p438\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oplex Careers => Time Required to Scrape 384 Records => 5.6 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape oplex careers\n",
    "oplexCareers = scrapeByProvider(\"https://www.reed.co.uk/courses/oplex-careers/p630\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxford Home Study College => Time Required to Scrape 193 Records => 2.22 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape oxford home study college\n",
    "oxford = scrapeByProvider(\"https://www.reed.co.uk/courses/oxford-home-study-college/p1245\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Terminal => Time Required to Scrape 88 Records => 1.11 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape training terminal\n",
    "trainingTerminal = scrapeByProvider(\"https://www.reed.co.uk/courses/the-training-terminal/p1064\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel with Business => Time Required to Scrape 60 Records => 0.91 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape excel with business\n",
    "excelWithBusiness = scrapeByProvider(\"https://www.reed.co.uk/courses/excel-with-business/p930\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OfCourse => Time Required to Scrape 647 Records => 7.44 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape ofcourse\n",
    "ofCourse = scrapeByProvider(\"https://www.reed.co.uk/courses/ofcourse/p675\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trendimi => Time Required to Scrape 40 Records => 0.59 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape trendimi\n",
    "trendimi = scrapeByProvider(\"https://www.reed.co.uk/courses/trendimi/p964\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centre of Excellence => Time Required to Scrape 348 Records => 3.81 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Scrape centre of excellence\n",
    "centreOfExcellence = scrapeByProvider(\"https://www.reed.co.uk/courses/centre-of-excellence-online/p652\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseId</th>\n",
       "      <th>courseTitle</th>\n",
       "      <th>subTitle</th>\n",
       "      <th>courseLink</th>\n",
       "      <th>courseProvider</th>\n",
       "      <th>unitSold</th>\n",
       "      <th>soldOrEnq</th>\n",
       "      <th>offerPrice</th>\n",
       "      <th>originalPrice</th>\n",
       "      <th>haveCpd</th>\n",
       "      <th>cpdAccreditedBy</th>\n",
       "      <th>othersAsCpd</th>\n",
       "      <th>haveProfQual</th>\n",
       "      <th>isRegulated</th>\n",
       "      <th>awrBodyName</th>\n",
       "      <th>awrBodyQualName</th>\n",
       "      <th>courseLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>234929</td>\n",
       "      <td>Car Mechanic Training</td>\n",
       "      <td>Level 3 Endorsed Diploma by TQUK | 15 CPD Poin...</td>\n",
       "      <td>https://www.reed.co.uk/courses/car-mechanic-tr...</td>\n",
       "      <td>One Education</td>\n",
       "      <td>1461</td>\n",
       "      <td>1,461 students purchased this course</td>\n",
       "      <td>14.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>missing</td>\n",
       "      <td>Training Qualifications UK Ltd</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>Training Qualifications UK Ltd</td>\n",
       "      <td>Level 3 Diploma in Car Mechanic (Endorsed Cert...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>233863</td>\n",
       "      <td>120 hours TEFL (TESOL) Masterclass</td>\n",
       "      <td>Level 3 Endorsed Diploma by TQUK | 40 CPD Poin...</td>\n",
       "      <td>https://www.reed.co.uk/courses/120-hours-tefl-...</td>\n",
       "      <td>One Education</td>\n",
       "      <td>668</td>\n",
       "      <td>668 students purchased this course</td>\n",
       "      <td>14.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>missing</td>\n",
       "      <td>Training Qualifications UK Ltd</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>Training Qualifications UK Ltd</td>\n",
       "      <td>Level 3 Diploma in TEFL/TESOL Masterclass (End...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>246722</td>\n",
       "      <td>Level 3 Award in Education and Training - AET ...</td>\n",
       "      <td>Awarded by TQUK I Ofqual Regulated I Free PDF ...</td>\n",
       "      <td>https://www.reed.co.uk/courses/level-3-award-i...</td>\n",
       "      <td>One Education</td>\n",
       "      <td>661</td>\n",
       "      <td>661 students purchased this course</td>\n",
       "      <td>10.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>no</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Training Qualifications UK Ltd</td>\n",
       "      <td>Level 3 Award in Education and Training (QCF)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>237280</td>\n",
       "      <td>Microsoft Excel Ultimate 5 Courses Bundle with...</td>\n",
       "      <td>Level 5 Endorsed Diploma by TQUK | 40 CPD Poin...</td>\n",
       "      <td>https://www.reed.co.uk/courses/microsoft-excel...</td>\n",
       "      <td>One Education</td>\n",
       "      <td>1425</td>\n",
       "      <td>1,425 students purchased this course</td>\n",
       "      <td>16.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>missing</td>\n",
       "      <td>Training Qualifications UK Ltd</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>Training Qualifications UK Ltd</td>\n",
       "      <td>Level 5 Diploma in Microsoft Excel (Endorsed C...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>233696</td>\n",
       "      <td>UK Employment Law</td>\n",
       "      <td>Level 5 Endorsed Diploma by TQUK | 20 CPD Poin...</td>\n",
       "      <td>https://www.reed.co.uk/courses/uk-employment-l...</td>\n",
       "      <td>One Education</td>\n",
       "      <td>1246</td>\n",
       "      <td>1,246 students purchased this course</td>\n",
       "      <td>14.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>missing</td>\n",
       "      <td>Training Qualifications UK Ltd</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>Training Qualifications UK Ltd</td>\n",
       "      <td>Level 5 Diploma in UK Employment Law (Endorsed...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  courseId                                        courseTitle  \\\n",
       "0   234929                              Car Mechanic Training   \n",
       "1   233863                 120 hours TEFL (TESOL) Masterclass   \n",
       "2   246722  Level 3 Award in Education and Training - AET ...   \n",
       "3   237280  Microsoft Excel Ultimate 5 Courses Bundle with...   \n",
       "4   233696                                  UK Employment Law   \n",
       "\n",
       "                                            subTitle  \\\n",
       "0  Level 3 Endorsed Diploma by TQUK | 15 CPD Poin...   \n",
       "1  Level 3 Endorsed Diploma by TQUK | 40 CPD Poin...   \n",
       "2  Awarded by TQUK I Ofqual Regulated I Free PDF ...   \n",
       "3  Level 5 Endorsed Diploma by TQUK | 40 CPD Poin...   \n",
       "4  Level 5 Endorsed Diploma by TQUK | 20 CPD Poin...   \n",
       "\n",
       "                                          courseLink courseProvider  unitSold  \\\n",
       "0  https://www.reed.co.uk/courses/car-mechanic-tr...  One Education      1461   \n",
       "1  https://www.reed.co.uk/courses/120-hours-tefl-...  One Education       668   \n",
       "2  https://www.reed.co.uk/courses/level-3-award-i...  One Education       661   \n",
       "3  https://www.reed.co.uk/courses/microsoft-excel...  One Education      1425   \n",
       "4  https://www.reed.co.uk/courses/uk-employment-l...  One Education      1246   \n",
       "\n",
       "                              soldOrEnq  offerPrice  originalPrice haveCpd  \\\n",
       "0  1,461 students purchased this course        14.0          199.0     yes   \n",
       "1    668 students purchased this course        14.0          199.0     yes   \n",
       "2    661 students purchased this course        10.0          399.0      no   \n",
       "3  1,425 students purchased this course        16.0          199.0     yes   \n",
       "4  1,246 students purchased this course        14.0          199.0     yes   \n",
       "\n",
       "  cpdAccreditedBy                     othersAsCpd haveProfQual isRegulated  \\\n",
       "0         missing  Training Qualifications UK Ltd          yes          no   \n",
       "1         missing  Training Qualifications UK Ltd          yes          no   \n",
       "2         missing                         missing          yes         yes   \n",
       "3         missing  Training Qualifications UK Ltd          yes          no   \n",
       "4         missing  Training Qualifications UK Ltd          yes          no   \n",
       "\n",
       "                      awrBodyName  \\\n",
       "0  Training Qualifications UK Ltd   \n",
       "1  Training Qualifications UK Ltd   \n",
       "2  Training Qualifications UK Ltd   \n",
       "3  Training Qualifications UK Ltd   \n",
       "4  Training Qualifications UK Ltd   \n",
       "\n",
       "                                     awrBodyQualName courseLevel  \n",
       "0  Level 3 Diploma in Car Mechanic (Endorsed Cert...           3  \n",
       "1  Level 3 Diploma in TEFL/TESOL Masterclass (End...           3  \n",
       "2      Level 3 Award in Education and Training (QCF)           3  \n",
       "3  Level 5 Diploma in Microsoft Excel (Endorsed C...           5  \n",
       "4  Level 5 Diploma in UK Employment Law (Endorsed...           5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat all the dataframes into one dataframe\n",
    "mergedDf = pd.concat([\n",
    "    oneEducation,\n",
    "    courseGate,\n",
    "    janets,\n",
    "    eustonCollege,\n",
    "    trainingExpress,\n",
    "    beaco,\n",
    "    cpdCourses,\n",
    "    brentwood,\n",
    "    oplexCareers,\n",
    "    oxford,\n",
    "    trainingTerminal,\n",
    "    excelWithBusiness,\n",
    "    ofCourse,\n",
    "    trendimi,\n",
    "    centreOfExcellence\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# Let's have a look at those data\n",
    "mergedDf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save the dataframe as csv file with today's date\n",
    "mergedDf.to_csv(f\"{today}_15_providers_cpdUpdated.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
